---
  title: "happiness_project"
output: html_document
---
  
  
  
```{r happiness, echo=FALSE}
#LOADING DATA AND DOWNLOADING PACKAGES

data = read.csv('https://raw.githubusercontent.com/arunagossai/happiness_project_R/master/happiness_data.csv', header = TRUE)
summary(data)
dim(data)
library(tseries)
library(fastDummies)
library(qdapTools)
library(glmnet)
library(rpart)
library(rpart.plot)
library(e1071)
library(caret)
```



```{r happiness, echo=FALSE}
#VARIABLE CREATION AND PREPROCESSING

#Creating a key for the regions to match region names to numeric values
regionkey = levels(data$region)
regionvalues = c(1:10)
key = data.frame(regionkey,regionvalues)
#Changing the region from categorical to numeric
data$region <- as.numeric(data$region)

#Change getting rid of countries with no observations, and countries with no democracy value
df1  = subset(data, country != "Kosovo"  & country !="Taiwan" & country!="Sudan" & democracy!= 'NA')
paste( dim(data)[1] - dim(df1)[1], "observations lost")

#Taking the mean of each column by country. Changes dataset from pooled cross-sectional to cross-sectional. This is done because each country does not have the same number of observations (years). Chose the mean instead of median because of the low variance between different years for one country.
df2 <- aggregate.data.frame(df1[-2], by = list(df1$country), mean)
paste( dim(df1)[1] - dim(df2)[1], "observations lost")
#adding a column for the region name
rname = lookup(df2$region,key$regionvalues,key$regionkey)
df3 = data.frame(df2,rname)
#Creating dummy variables from the region name
df <- dummy_cols(df3, select_columns = "rname")

#testing for multicollinearity excluding regions and year from matrix
cor(df[6:15])
#serious issues with multicollinearity, dropping the problem variables
df$men_edu <- NULL
df$sanitation <- NULL
df$elder_child <- NULL
df$child_mortality <- NULL

#creating binary 'very happy' variables for classification models
df$veryhappy <- ifelse(df$happiness >= 6.5,1,0)

#dropping variables that are not needed
df$year <- NULL
df$Ã¯..id <- NULL
df$id <- NULL
df$region <- NULL
df$rname <- NULL  #getting rid of one dummy variable to prevent multicollinearity
df$rname_West_EU<-NULL
```




```{r happiness, echo=FALSE}
#CHECKING VARIABLE RELATIONSHIPS WITH DEPENDENT VARIABLE

#graphically viewing relationships between independent and dependent variables
hist(df$happiness)
jarque.bera.test(df$happiness) #happiness is not normally distributed
plot(df$women_edu,df$happiness)
plot(log(df$women_edu),df$happiness)#women_edu seems to fit better with log(women_edu)
plot(df$democracy,df$happiness) #democracy variable seems to have a linear relationship
plot(df$gini,df$happiness) 
plot(log(df$gini),df$happiness) #gini seems uncorrelated to happiness
plot(df$gini^2,df$happiness) #the log or squared of gini does not help the fit
plot(df$refugee,df$happiness) 
plot(df$refugee,df$happiness, xlim = c(0,1))
plot(log(df$refugee + 1),df$happiness)
plot(log(df$refugee + 1),df$happiness, xlim = c(0,1)) # refugee share does not seem to be correlated, log helps with variance
plot(df$pop_den,df$happiness)
plot(log(df$pop_den),df$happiness) # pop not seems uncorrelated. log noticably reduces variance
plot(df$labour,df$happiness)
plot(log(df$labour),df$happiness)
plot(df$labour,log(df$happiness)) #labour seems uncorrelated to happiness
```




```{r}
#TRANSFORMING VARIABLES AND CREATING TEST AND TRAINING SET

#transformations
df1 = df
df1$refugee <- log(df1$refugee+1)
df1$women_edu <- log(df1$women_edu)
df1$pop_den <- log(df1$pop_den)

#test/training split
Index = sample(1:nrow(df), size = round(0.7*nrow(df)), replace=FALSE)
train = df1[Index,]
test = df1[-Index,]
```




```{r}
#MODEL 1: BASE FOR MODEL COMPARISION: REGRESSION

#Building linear model including all the variables in transformed dataset
M1 = lm(happiness ~ ., train[2:17])

pred_in_1 = predict(M1, train[3:17])
pred_out_1 = predict(M1, test[3:17])

#Model validation using root mean squared error
RMSE_IN_1 = sqrt(sum((pred_in_1-train$happiness)^2)/length(pred_in_1))
RMSE_OUT_1 = sqrt(sum((pred_out_1-test$happiness)^2)/length(pred_out_1))

c(RMSE_IN_1,RMSE_OUT_1)
```




```{r}
#MODEL 2: PENALIZED REGRESSION WITH A 5 FOLD CROSS VALIDATION

#model selection - using RMSE to decide between ridge, lasso, and blended penalties 
results <- c()
alpha = c(0,.25,.5,.75,1)
for(i in 1:5){
  M2 = cv.glmnet(as.matrix(train[3:17]),train$happiness, alpha = alpha[i], nfolds = 5)
  
  pred_in_2 = predict(M2, as.matrix(train[3:17]), s = 'lambda.min')
  pred_out_2 = predict(M2, as.matrix(test[3:17]), s = 'lambda.min')
  
  RMSE_IN_2 = sqrt(sum((pred_in_2-train$happiness)^2)/length(pred_in_2))
  RMSE_OUT_2 = sqrt(sum((pred_out_2-test$happiness)^2)/length(pred_out_2))
  
  results <- rbind(results,c(alpha[i],RMSE_IN_2,RMSE_OUT_2,M2$lambda.min))
  colnames(results)<-c("Alpha","RMSE_IN","RMSE_OUT","Lambda")
}
results

#finding the penalty term that produced the smallest RMSE
MIN_ERROR = results[which(results[,3] == min(results[,3])),]
MIN_ERROR

#building regression with penalty term corresponding to lowest RMSE
M2 = cv.glmnet(as.matrix(train[3:17]),train$happiness, alpha = MIN_ERROR[1], nfolds = 5)

pred_in_2 = predict(M2, as.matrix(train[3:17]), s = 'lambda.min')
pred_out_2 = predict(M2, as.matrix(test[3:17]), s = 'lambda.min')

RMSE_IN_2 = sqrt(sum((pred_in_2-train$happiness)^2)/length(pred_in_2))
RMSE_OUT_2 = sqrt(sum((pred_out_2-test$happiness)^2)/length(pred_out_2))

R2 <- M2$glmnet.fit$dev.ratio[which(M2$glmnet.fit$lambda == M2$lambda.min)]
#the lower the number the better for RMSE
data.frame( data = c(RMSE_OUT_1,RMSE_OUT_2,RMSE_IN_2,R2), row.names = c("RMSE Out Base","Penalty RMSE Out","Penalty RMSE In","Penalty R-Squared"))

#cbind(coef(M2, s = 'lambda.min')) #coefficients of variables

```




```{r}
#MODEL 3: BASE MODEL FOR COMPARISON: CLASSIFICATION

#building basic logistic regression model with all variables 
M3<-glm(veryhappy ~ ., data = train[3:18], family = binomial())

CONFUSION_IN_3 = confusionMatrix(table(predict(M3, train, type="response")
                                       >= 0.5,train$veryhappy == 1))
CONFUSION_OUT_3 = confusionMatrix(table(predict(M3, test, type="response")
                                        >= 0.5,test$veryhappy == 1))
CONFUSION_IN_3$table
CONFUSION_OUT_3$table
c(CONFUSION_OUT_3$overall[1])
```





```{r}
#MODEL 4: SUPPORT VECTOR MACHINE CLASSIFICATION WITH 5 FOLD CROSS-VALIDATION

#model selection - using accuracy to determine the level of gamma
SVM_results = c()
gamma = c(.5,.1,.05,.01,.005)
for (i in 1:5){
  SVM<-svm(veryhappy~ ., data = train[3:18], kernel = "radial", gamma = gamma[i], type="C-classification", cross = 5)
 
  SVM_IN =  predict(SVM, train)
  SVM_OUT =  predict(SVM, test)
 
  confusion_IN_4 = table(SVM_IN,train$veryhappy)
  confusion_OUT_4 = table(SVM_OUT,test$veryhappy)
 
  Accuracy_IN_4 = (confusion_IN_4[1,1]+confusion_IN_4[2,2])/length(SVM_IN)
  Accuracy_OUT_4 = (confusion_OUT_4[1,1]+confusion_OUT_4[2,2])/length(SVM_OUT)
 
  SVM_results <- rbind(SVM_results,c(gamma[i],Accuracy_IN_4,Accuracy_OUT_4))
  colnames(SVM_results)<-c("Gamma","Accuracy In","Accuracy Out")
}
SVM_results
MAX_ACC = SVM_results[which(SVM_results[,3] == max(SVM_results[,3])),]
MAX_ACC
 
#building model using the value of gamma that produced the highest accuracy
M4<-svm(veryhappy~ ., data = train[3:18], kernel = "radial", gamma = MAX_ACC[1], type="C-classification")

pred_in_4 =  predict(M4, train)
pred_out_4 = predict(M4, test)

CONFUSION_IN_4 = confusionMatrix(table(pred_in_4,train$veryhappy))
CONFUSION_OUT_4 = confusionMatrix(table(pred_out_4,test$veryhappy))

#creating final table to compare base model to SVM
{
  titles = c("Accuracy","Sensitivity","Precision","Recall")
  SVM_Stats = c(CONFUSION_OUT_4$overall[1],CONFUSION_OUT_4$byClass[1],CONFUSION_OUT_4$byClass[5],CONFUSION_OUT_4$byClass[6])
  Base_Stats = c(CONFUSION_OUT_3$overall[1],CONFUSION_OUT_3$byClass[1],CONFUSION_OUT_3$byClass[5],CONFUSION_OUT_3$byClass[6])
  } 

final = data.frame(c(data.frame(Base_Stats),data.frame(SVM_Stats)), row.names = titles)
colnames(final) <- c("BASE","SVM")
final
#t(M5$coefs)%*% M5$SV #code to get the coefficients
```


```{r}
#RESIDUAL ANALYSIS OF MODEL 2 (PENALIZED REGRESSION)

plot(pred_out_2-test$happiness) 
abline(0,0,col='black') #residuals appear to be randomly dispersed
summary(pred_out_2-test$happiness) #mean and median are close to 0
jarque.bera.test(pred_out_2-test$happiness) #null: normally distributed
```

